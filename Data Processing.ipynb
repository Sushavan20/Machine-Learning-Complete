{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb0bab8",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bdc04",
   "metadata": {},
   "source": [
    "##### Data preprocessing is a process of preparing the raw data and making it suitable for a machine learning model. It is the first and crucial step while creating a machine learning model.\n",
    "1. Getting the dataset\n",
    "2. Importing libraries\n",
    "3. Importing datasets\n",
    "4. Finding Missing Data\n",
    "5. Encoding Categorical Data\n",
    "6. Splitting dataset into training and test set\n",
    "7. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059a5b83",
   "metadata": {},
   "source": [
    "**> Getting the dataset**\n",
    "* To use the dataset in our code, we usually put it into a CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f54ea",
   "metadata": {},
   "source": [
    "**> Import librery**\n",
    "* In order to perform data preprocessing using Python, we need to import some predefined Python libraries. These libraries are used to perform some specific jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e73fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f13b0",
   "metadata": {},
   "source": [
    "**> Importing the dataset**\n",
    "* Now we need to import the datasets which we have collected for our machine learning project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d31482",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data_data_processing.csv') \n",
    "X = dataset.iloc[:,:-1].values #[rows,column] -> all rows and columns expect last column\n",
    "Y = dataset.iloc[:,3].values #[rows,column] -> all rows and last columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595325f",
   "metadata": {},
   "source": [
    "**> Resolving missing data**\n",
    "* The next step of data preprocessing is to handle missing data in the datasets. If our dataset contains some missing data, then it may create a huge problem for our machine learning model. Hence it is necessary to handle missing values present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97069e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean') # missing places will be filled with mean value of the column\n",
    "imputer = imputer.fit(X[:,1:3])\n",
    "X[:,1:3] = imputer.transform(X[:,1:3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33e0e7",
   "metadata": {},
   "source": [
    "**> Encoding categorical data**\n",
    "* Since machine learning model completely works on mathematics and numbers, but if our dataset would have a categorical variable, then it may create trouble while building the model. So it is necessary to encode these categorical variables into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a956ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelEncoder_X = LabelEncoder()\n",
    "X[:,0] = labelEncoder_X.fit_transform(X[:,0])\n",
    "onehotencoder = ColumnTransformer([(\"Country\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X = onehotencoder.fit_transform(X)\n",
    "labelEncoder_Y = LabelEncoder()\n",
    "Y = labelEncoder_Y.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d15ed",
   "metadata": {},
   "source": [
    "**> Split dataset in Training and Testing**\n",
    "* In machine learning data preprocessing, we divide our dataset into a training set and test set. This is one of the crucial steps of data preprocessing as by doing this, we can enhance the performance of our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e9de75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df265714",
   "metadata": {},
   "source": [
    "**> Feature Scaling -> Putting variables in a static range to eliminate bais**\n",
    "* Feature scaling is the final step of data preprocessing in machine learning. It is a technique to standardize the independent variables of the dataset in a specific range. In feature scaling, we put our variables in the same range and in the same scale so that no any variable dominate the other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d125110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae7129",
   "metadata": {},
   "source": [
    "#### In the above code, we have included all the data preprocessing steps together. But there are some steps or lines of code which are not necessary for all machine learning models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
